{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subsequent-hazard",
   "metadata": {},
   "source": [
    "# Travail pratique 4\n",
    "*INF600F - Traitement d'images (H2022, UQÀM)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-generation",
   "metadata": {},
   "source": [
    "* Indiquez ici votre prénom/nom et code permanent.\n",
    "* Modifiez aussi le nom du notebook pour qu'il ait ce format : `TP3-NOM1_NOM2`, où `NOM{k}` est le nom de famille de chaque membre de votre équipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passing-museum",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology, filters, segmentation, measure, transform\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.color import label2rgb\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-joining",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercice 1 : Reconnaissance de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107e6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d50b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_randomImages(imageList):\n",
    "    limit = len(imageList)\n",
    "    choices = []\n",
    "    i = 0;\n",
    "    while(i < 12):\n",
    "        temp = np.random.randint(limit - 1)\n",
    "        while(temp in choices):\n",
    "            temp = np.random.randint(limit - 1)\n",
    "        choices.append(temp)\n",
    "        i+=1\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(141); plt.imshow(imageList[choices[0]], cmap='gray'); plt.title([choices[0]])\n",
    "    plt.subplot(142); plt.imshow(imageList[choices[1]], cmap='gray'); plt.title([choices[1]])\n",
    "    plt.subplot(143); plt.imshow(imageList[choices[2]], cmap='gray'); plt.title([choices[2]])\n",
    "    plt.subplot(144); plt.imshow(imageList[choices[3]], cmap='gray'); plt.title([choices[3]])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(141); plt.imshow(imageList[choices[4]], cmap='gray'); plt.title([choices[4]])\n",
    "    plt.subplot(142); plt.imshow(imageList[choices[5]], cmap='gray'); plt.title([choices[5]])\n",
    "    plt.subplot(143); plt.imshow(imageList[choices[6]], cmap='gray'); plt.title([choices[6]])\n",
    "    plt.subplot(144); plt.imshow(imageList[choices[7]], cmap='gray'); plt.title([choices[7]])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(141); plt.imshow(imageList[choices[8]], cmap='gray'); plt.title([choices[8]])\n",
    "    plt.subplot(142); plt.imshow(imageList[choices[9]], cmap='gray'); plt.title([choices[9]])\n",
    "    plt.subplot(143); plt.imshow(imageList[choices[10]], cmap='gray'); plt.title([choices[10]])\n",
    "    plt.subplot(144); plt.imshow(imageList[choices[11]], cmap='gray'); plt.title([choices[11]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a002e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread('tp4_ex1.png')\n",
    "\n",
    "'''\n",
    "    Phase de Pretraitement du pipeline\n",
    "'''\n",
    "# conversion en tons de gris et en float\n",
    "image_grayscale = image.mean(axis=2).astype(float)\n",
    "\n",
    "# normalisation de l'intensite\n",
    "image_grayscale_norm = (image_grayscale / 255)\n",
    "\n",
    "# inversion des intensite\n",
    "image_grayscale_norm_inv = (1 - image_grayscale_norm)\n",
    "\n",
    "'''\n",
    "    Phase de segmentation du pipeline, extraction et sauvegarde dans une liste d'image\n",
    "'''\n",
    "# Appliquer un filtrage par ouverture-fermeture morphologiques pour effacer l'arriere plan, \n",
    "# et par la meme occasion remplir des trous eventuels dans nos lettres\n",
    "# Creation d'un element structurant 3 x 3\n",
    "h = np.ones((3,3))\n",
    "\n",
    "# appliquer une ouverture avec notre element structurant afin de retirer les bruit de l'arriere plan\n",
    "image_opening = morphology.opening(image_grayscale_norm_inv, h)\n",
    "# appliquer une fermeture afin de remplir d'eventuels trous\n",
    "image_closing =  morphology.closing(image_opening, h)\n",
    "# seuillage par methode otsu\n",
    "threshold = filters.threshold_otsu(image_closing)\n",
    "image_segmented = image_closing > threshold\n",
    "\n",
    "# retirer les lettres touchant la bordure\n",
    "image_lucid_borders = segmentation.clear_border(image_segmented)\n",
    "\n",
    "# Etiqueter (label) les lettres\n",
    "image_labeled = measure.label(image_lucid_borders)\n",
    "\n",
    "\n",
    "# apres differents tests, ce seuil permet de garder un maximum de lettre en ignorant la ponctuation\n",
    "area_limit = 150\n",
    "\n",
    "# Creer la liste des images de lettres\n",
    "image_list = []\n",
    "\n",
    "# boucler sur les lettres detectees\n",
    "for region in measure.regionprops(image_labeled):\n",
    "    if region.area >= area_limit:\n",
    "        tempo = transform.resize(region.image, (24,24))\n",
    "        image_list.append(tempo)\n",
    "\n",
    "        \n",
    "'''\n",
    "    Cette section est la pour demontrer les differentes etapes du pipeline utilisees. Decommenter pour voir \n",
    "    le cheminement du pipeline.\n",
    "    \n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121); plt.imshow(image); plt.title('image originale')\n",
    "plt.subplot(122); plt.imshow(image_grayscale, cmap='gray'); plt.title('image tons gris')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121); plt.imshow(image_grayscale_norm ,cmap='gray'); plt.title('image tons gris normalise')\n",
    "plt.subplot(122); plt.imshow(image_grayscale_norm_inv,cmap='gray' ); plt.title('image tons gris normalise inverse')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121); plt.imshow(image_opening,cmap='gray' ); plt.title('opening')\n",
    "plt.subplot(122); plt.imshow(image_closing,cmap='gray'); plt.title('closing')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121); plt.imshow(image_segmented ,cmap='gray'); plt.title('image segmented')\n",
    "plt.subplot(122); plt.imshow(image_lucid_borders ,cmap='gray'); plt.title('image segmented clean borders')\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "# Appel de la fonction d'affichage\n",
    "display_randomImages(image_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a57182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "## Le nombre de lettres détectées dans cette image : 608\n",
    "\n",
    "# Question 2\n",
    "## Une situation ou le pipeline de traitement d’images échoue à extraire une lettre isolée est les suivantes : \n",
    "## \"pe\", \"to\", \"oc\", \"se\" : ce qui s'explique par l'existence d'une frontiere commune entre les deux lettres\n",
    "## afin d'ameliorer les performance, il faudrait performer une erosion apres la fermeture (lors de la segmentation)\n",
    "## mais qui ne corrompt pas le resultat. Aussi envisager de changer le area_limit qui est le nombre de pixel \n",
    "## dans les regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71401d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1eb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_features = 500\n",
    "nbr_images = len(image_list)\n",
    "i = 0\n",
    "for i in range(len(image_list)):\n",
    "    X = transform.resize(image_list[i], (nbr_images,average_features))\n",
    "    kmeans_cluster = cluster.KMeans(n_clusters=26)\n",
    "    kmeans_cluster.fit(X)\n",
    "    cluster_centers = kmeans_cluster.cluster_centers_\n",
    "    cluster_labels = kmeans_cluster.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-opera",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercice 2 : Compter des cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "written-seminar",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de cellules estime de cette image est de 255 cellules.\n"
     ]
    }
   ],
   "source": [
    "image2 = imageio.imread(\"tp4_ex2.tif\")\n",
    "image2_norm = (image2 / 255).astype(float)\n",
    "nb = 0\n",
    "\n",
    "\n",
    "# seuillage par methode otsu\n",
    "threshold = filters.threshold_otsu(image2_norm)\n",
    "image2_segmented = image2_norm > threshold\n",
    "\n",
    "\n",
    "# Creation d'un element structurant 3 x 3 en forme de disque (apres des recherches, ce kernel semble approprie)\n",
    "h2 = morphology.disk(2)\n",
    "\n",
    "# appliquer une fermeture afin de remplir d'eventuels trous\n",
    "image2_closing =  morphology.closing(image2_segmented, h2)\n",
    "\n",
    "# Etiqueter (label) les cellules\n",
    "image2_labeled = measure.label(image2_closing)\n",
    "\n",
    "# nombre minimum admis de pixels par cellules (apres multiples tentatives, ce chiffre correspond au nombre\n",
    "# le plus optimal afin de detecter le maximum de cellules)\n",
    "limit_region = 5\n",
    "\n",
    "# boucler sur les cellules detectees afin d'en trouver le nombre\n",
    "for region in measure.regionprops(image2_labeled):\n",
    "    if region.area >= limit_region:\n",
    "        nb+=1\n",
    "\n",
    "        \n",
    "'''\n",
    "    Cette section est la pour demontrer les differentes etapes Decommenter pour voir \n",
    "    le cheminement de la solution\n",
    "    \n",
    "# affichage\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121); plt.imshow(image2_segmented, cmap='gray');plt.title('image segmented')\n",
    "plt.subplot(122); plt.imshow(image2_closing, cmap='gray');plt.title('image closing')\n",
    "plt.show()\n",
    "'''\n",
    "        \n",
    "\n",
    "# verification afin de savoir si le pluriel devrait etre utilise ou pas selon le nombre de cellule\n",
    "\n",
    "mot = 'cellules.' if nb > 1 else 'cellule.'\n",
    "        \n",
    "print('Le nombre de cellules estimées de cette image est de ' + str(nb) + ' ' + mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b32e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
